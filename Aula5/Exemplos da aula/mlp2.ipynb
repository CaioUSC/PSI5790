{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# !pip uninstall tensorflow -y --quiet\n",
        "# !pip install tensorflow==2.15 --quiet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5x0hCQv5aIlw",
        "outputId": "50421228-792d-4bba-80a4-1e49efb907f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.2/475.2 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m73.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m98.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorstore 0.1.71 requires ml_dtypes>=0.3.1, but you have ml-dtypes 0.2.0 which is incompatible.\n",
            "tf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.15.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4aVP3czWi1v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8066d06c-1434-4357-8e36-9a5365220504"
      },
      "source": [
        "# mlp2.py\n",
        "import os; os.environ['TF_CPP_MIN_LOG_LEVEL']='3'\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Normalization\n",
        "from tensorflow.keras import optimizers\n",
        "import numpy as np; import sys\n",
        "\n",
        "(AX, AY), (QX, QY) = mnist.load_data()\n",
        "AX=255-AX; QX=255-QX\n",
        "\n",
        "nclasses = 10\n",
        "AY2 = keras.utils.to_categorical(AY, nclasses)\n",
        "QY2 = keras.utils.to_categorical(QY, nclasses)\n",
        "\n",
        "nl, nc = AX.shape[1], AX.shape[2] #28, 28\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Normalization(input_shape=(nl,nc))) #Normaliza\n",
        "model.add(Flatten())\n",
        "model.add(Dense(400, activation='relu'))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dense(nclasses, activation='softmax'))\n",
        "\n",
        "opt=optimizers.Adam(learning_rate=0.0005)\n",
        "# como usou a softmax teve que mudar a função de erro para categorical_crossentropy\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.get_layer(index=0).adapt(AX) #Calcula media e desvio\n",
        "model.fit(AX, AY2, batch_size=100, epochs=80, verbose=2);\n",
        "\n",
        "score = model.evaluate(QX, QY2, verbose=False)\n",
        "print('Test loss: %.4f'%(score[0]))\n",
        "print('Test accuracy: %.2f %%'%(100*score[1]))\n",
        "print('Test error: %.2f %%'%(100*(1-score[1])))\n",
        "model.save('mlp2.keras')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/preprocessing/tf_data_layer.py:19: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/80\n",
            "600/600 - 5s - 8ms/step - accuracy: 0.9267 - loss: 0.2502\n",
            "Epoch 2/80\n",
            "600/600 - 1s - 2ms/step - accuracy: 0.9723 - loss: 0.0946\n",
            "Epoch 3/80\n",
            "600/600 - 1s - 2ms/step - accuracy: 0.9834 - loss: 0.0564\n",
            "Epoch 4/80\n",
            "600/600 - 1s - 2ms/step - accuracy: 0.9888 - loss: 0.0374\n",
            "Epoch 5/80\n",
            "600/600 - 1s - 2ms/step - accuracy: 0.9923 - loss: 0.0260\n",
            "Epoch 6/80\n",
            "600/600 - 1s - 2ms/step - accuracy: 0.9944 - loss: 0.0207\n",
            "Epoch 7/80\n",
            "600/600 - 1s - 2ms/step - accuracy: 0.9943 - loss: 0.0203\n",
            "Epoch 8/80\n",
            "600/600 - 1s - 2ms/step - accuracy: 0.9959 - loss: 0.0134\n",
            "Epoch 9/80\n",
            "600/600 - 1s - 2ms/step - accuracy: 0.9959 - loss: 0.0136\n",
            "Epoch 10/80\n",
            "600/600 - 1s - 2ms/step - accuracy: 0.9979 - loss: 0.0075\n",
            "Epoch 11/80\n",
            "600/600 - 2s - 3ms/step - accuracy: 0.9974 - loss: 0.0082\n",
            "Epoch 12/80\n",
            "600/600 - 1s - 2ms/step - accuracy: 0.9956 - loss: 0.0131\n",
            "Epoch 13/80\n",
            "600/600 - 1s - 2ms/step - accuracy: 0.9985 - loss: 0.0054\n",
            "Epoch 14/80\n",
            "600/600 - 1s - 2ms/step - accuracy: 0.9986 - loss: 0.0045\n",
            "Epoch 15/80\n",
            "600/600 - 1s - 2ms/step - accuracy: 0.9972 - loss: 0.0091\n",
            "Epoch 16/80\n",
            "600/600 - 1s - 2ms/step - accuracy: 0.9971 - loss: 0.0089\n",
            "Epoch 17/80\n",
            "600/600 - 1s - 2ms/step - accuracy: 0.9972 - loss: 0.0083\n",
            "Epoch 18/80\n",
            "600/600 - 1s - 2ms/step - accuracy: 0.9982 - loss: 0.0057\n",
            "Epoch 19/80\n",
            "600/600 - 1s - 2ms/step - accuracy: 0.9979 - loss: 0.0079\n",
            "Epoch 20/80\n",
            "600/600 - 2s - 3ms/step - accuracy: 0.9990 - loss: 0.0036\n",
            "Epoch 21/80\n",
            "600/600 - 1s - 2ms/step - accuracy: 0.9988 - loss: 0.0037\n",
            "Epoch 22/80\n",
            "600/600 - 1s - 2ms/step - accuracy: 0.9976 - loss: 0.0071\n",
            "Epoch 23/80\n",
            "600/600 - 1s - 2ms/step - accuracy: 0.9981 - loss: 0.0070\n",
            "Epoch 24/80\n",
            "600/600 - 1s - 2ms/step - accuracy: 0.9988 - loss: 0.0041\n",
            "Epoch 25/80\n",
            "600/600 - 1s - 2ms/step - accuracy: 0.9994 - loss: 0.0019\n",
            "Epoch 26/80\n",
            "600/600 - 1s - 2ms/step - accuracy: 0.9976 - loss: 0.0077\n",
            "Epoch 27/80\n",
            "600/600 - 1s - 2ms/step - accuracy: 0.9980 - loss: 0.0058\n",
            "Epoch 28/80\n",
            "600/600 - 1s - 2ms/step - accuracy: 0.9985 - loss: 0.0048\n",
            "Epoch 29/80\n",
            "600/600 - 1s - 2ms/step - accuracy: 0.9994 - loss: 0.0026\n",
            "Epoch 30/80\n",
            "600/600 - 1s - 2ms/step - accuracy: 0.9990 - loss: 0.0035\n",
            "Epoch 31/80\n",
            "600/600 - 1s - 2ms/step - accuracy: 0.9979 - loss: 0.0070\n",
            "Epoch 32/80\n",
            "600/600 - 1s - 2ms/step - accuracy: 0.9990 - loss: 0.0032\n",
            "Epoch 33/80\n",
            "600/600 - 1s - 2ms/step - accuracy: 0.9988 - loss: 0.0041\n",
            "Epoch 34/80\n",
            "600/600 - 1s - 2ms/step - accuracy: 0.9988 - loss: 0.0040\n",
            "Epoch 35/80\n",
            "600/600 - 1s - 2ms/step - accuracy: 0.9985 - loss: 0.0053\n",
            "Epoch 36/80\n",
            "600/600 - 1s - 2ms/step - accuracy: 0.9997 - loss: 0.0011\n",
            "Epoch 37/80\n",
            "600/600 - 1s - 2ms/step - accuracy: 0.9997 - loss: 0.0013\n",
            "Epoch 38/80\n",
            "600/600 - 1s - 2ms/step - accuracy: 1.0000 - loss: 1.3790e-04\n",
            "Epoch 39/80\n",
            "600/600 - 1s - 2ms/step - accuracy: 1.0000 - loss: 2.6796e-05\n",
            "Epoch 40/80\n",
            "600/600 - 1s - 2ms/step - accuracy: 1.0000 - loss: 1.4653e-05\n",
            "Epoch 41/80\n",
            "600/600 - 1s - 2ms/step - accuracy: 1.0000 - loss: 1.0947e-05\n",
            "Epoch 42/80\n",
            "600/600 - 1s - 2ms/step - accuracy: 1.0000 - loss: 8.6932e-06\n",
            "Epoch 43/80\n",
            "600/600 - 1s - 2ms/step - accuracy: 1.0000 - loss: 6.9211e-06\n",
            "Epoch 44/80\n",
            "600/600 - 1s - 2ms/step - accuracy: 1.0000 - loss: 5.4701e-06\n",
            "Epoch 45/80\n",
            "600/600 - 1s - 2ms/step - accuracy: 1.0000 - loss: 4.3988e-06\n",
            "Epoch 46/80\n",
            "600/600 - 1s - 2ms/step - accuracy: 1.0000 - loss: 3.4905e-06\n",
            "Epoch 47/80\n",
            "600/600 - 1s - 2ms/step - accuracy: 1.0000 - loss: 2.7441e-06\n",
            "Epoch 48/80\n",
            "600/600 - 1s - 2ms/step - accuracy: 1.0000 - loss: 2.1163e-06\n",
            "Epoch 49/80\n",
            "600/600 - 1s - 2ms/step - accuracy: 1.0000 - loss: 1.6730e-06\n",
            "Epoch 50/80\n",
            "600/600 - 1s - 2ms/step - accuracy: 1.0000 - loss: 1.3283e-06\n",
            "Epoch 51/80\n",
            "600/600 - 1s - 2ms/step - accuracy: 1.0000 - loss: 1.0146e-06\n",
            "Epoch 52/80\n",
            "600/600 - 1s - 2ms/step - accuracy: 1.0000 - loss: 7.8401e-07\n",
            "Epoch 53/80\n",
            "600/600 - 1s - 2ms/step - accuracy: 1.0000 - loss: 5.9714e-07\n",
            "Epoch 54/80\n",
            "600/600 - 2s - 4ms/step - accuracy: 1.0000 - loss: 5.0182e-07\n",
            "Epoch 55/80\n",
            "600/600 - 1s - 2ms/step - accuracy: 1.0000 - loss: 3.8391e-07\n",
            "Epoch 56/80\n",
            "600/600 - 1s - 2ms/step - accuracy: 1.0000 - loss: 2.7683e-07\n",
            "Epoch 57/80\n",
            "600/600 - 1s - 2ms/step - accuracy: 1.0000 - loss: 2.1339e-07\n",
            "Epoch 58/80\n",
            "600/600 - 1s - 2ms/step - accuracy: 0.9967 - loss: 0.0152\n",
            "Epoch 59/80\n",
            "600/600 - 1s - 2ms/step - accuracy: 0.9960 - loss: 0.0184\n",
            "Epoch 60/80\n",
            "600/600 - 1s - 2ms/step - accuracy: 0.9991 - loss: 0.0039\n",
            "Epoch 61/80\n",
            "600/600 - 1s - 2ms/step - accuracy: 0.9994 - loss: 0.0041\n",
            "Epoch 62/80\n",
            "600/600 - 2s - 3ms/step - accuracy: 0.9988 - loss: 0.0078\n",
            "Epoch 63/80\n",
            "600/600 - 2s - 4ms/step - accuracy: 0.9992 - loss: 0.0044\n",
            "Epoch 64/80\n",
            "600/600 - 1s - 2ms/step - accuracy: 0.9998 - loss: 6.9532e-04\n",
            "Epoch 65/80\n",
            "600/600 - 1s - 2ms/step - accuracy: 1.0000 - loss: 5.3728e-05\n",
            "Epoch 66/80\n",
            "600/600 - 1s - 2ms/step - accuracy: 1.0000 - loss: 2.8476e-05\n",
            "Epoch 67/80\n",
            "600/600 - 1s - 2ms/step - accuracy: 1.0000 - loss: 1.7521e-05\n",
            "Epoch 68/80\n",
            "600/600 - 1s - 2ms/step - accuracy: 1.0000 - loss: 1.3712e-05\n",
            "Epoch 69/80\n",
            "600/600 - 1s - 2ms/step - accuracy: 1.0000 - loss: 1.0914e-05\n",
            "Epoch 70/80\n",
            "600/600 - 1s - 2ms/step - accuracy: 1.0000 - loss: 8.6440e-06\n",
            "Epoch 71/80\n",
            "600/600 - 2s - 3ms/step - accuracy: 1.0000 - loss: 6.8398e-06\n",
            "Epoch 72/80\n",
            "600/600 - 1s - 2ms/step - accuracy: 1.0000 - loss: 5.4361e-06\n",
            "Epoch 73/80\n",
            "600/600 - 1s - 2ms/step - accuracy: 1.0000 - loss: 4.2483e-06\n",
            "Epoch 74/80\n",
            "600/600 - 1s - 2ms/step - accuracy: 1.0000 - loss: 3.3429e-06\n",
            "Epoch 75/80\n",
            "600/600 - 1s - 2ms/step - accuracy: 1.0000 - loss: 2.5843e-06\n",
            "Epoch 76/80\n",
            "600/600 - 1s - 2ms/step - accuracy: 1.0000 - loss: 2.0300e-06\n",
            "Epoch 77/80\n",
            "600/600 - 1s - 2ms/step - accuracy: 1.0000 - loss: 1.6328e-06\n",
            "Epoch 78/80\n",
            "600/600 - 1s - 2ms/step - accuracy: 0.9995 - loss: 0.0020\n",
            "Epoch 79/80\n",
            "600/600 - 1s - 2ms/step - accuracy: 0.9949 - loss: 0.0219\n",
            "Epoch 80/80\n",
            "600/600 - 1s - 2ms/step - accuracy: 0.9988 - loss: 0.0051\n",
            "Test loss: 0.1808\n",
            "Test accuracy: 98.08 %\n",
            "Test error: 1.92 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "my4r14-HomEW",
        "outputId": "e39d3ae2-7592-4bb9-c647-1ff4e39ba656",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#pred2.py\n",
        "import os; os.environ['TF_CPP_MIN_LOG_LEVEL']='3'\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "(_,_), (QX, QY) = mnist.load_data()\n",
        "QX=255-QX\n",
        "\n",
        "nclasses = 10\n",
        "QY2 = keras.utils.to_categorical(QY, nclasses)\n",
        "nl, nc = QX.shape[1], QX.shape[2] #28, 28\n",
        "\n",
        "model=load_model('mlp2.keras')\n",
        "score = model.evaluate(QX, QY2, verbose=False)\n",
        "print('Test loss: %.4f'%(score[0]))\n",
        "print('Test accuracy: %.2f %%'%(100*score[1]))\n",
        "print('Test error: %.2f %%'%(100*(1-score[1])))\n",
        "\n",
        "QP2 = model.predict(QX); QP = QP2.argmax(axis=1)\n",
        "print(QP2[0])\n",
        "print(QP[0])\n",
        "#Aqui QP contem as 10000 predicoes\n",
        "print(\"Imagem-teste 0: Rotulo verdadeiro=%d, predicao=%d\"%(QY[0],QP[0]))\n",
        "print(\"Imagem-teste 1: Rotulo verdadeiro=%d, predicao=%d\"%(QY[1],QP[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.2140\n",
            "Test accuracy: 97.90 %\n",
            "Test error: 2.10 %\n",
            "313/313 [==============================] - 1s 2ms/step\n",
            "[1.2184994e-38 1.3615631e-27 4.6658247e-29 7.7322288e-18 8.8239140e-26\n",
            " 1.5799965e-33 0.0000000e+00 1.0000000e+00 6.7217944e-27 4.4224917e-20]\n",
            "7\n",
            "Imagem-teste 0: Rotulo verdadeiro=7, predicao=7\n",
            "Imagem-teste 1: Rotulo verdadeiro=2, predicao=2\n"
          ]
        }
      ]
    }
  ]
}